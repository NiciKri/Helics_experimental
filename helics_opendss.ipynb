{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import os\n",
    "import helics as h\n",
    "import pandas as pd\n",
    "import config  # Import the configuration\n",
    "\n",
    "# Set the working directory using the configuration\n",
    "os.chdir(config.BASE_DIR)\n",
    "\n",
    "# Import federates from the package\n",
    "from federates import opendss_federate, voltage_consumer_federate, inverter_federate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import solar production data. Remove the '_pv' suffix if present and \n",
    "# replace all occurrences of capital \"S\" with lower-case \"s\".\n",
    "solar_data = pd.read_csv(f\"{config.DATA_DIR}/solar_data.csv\")\n",
    "solar_data.columns = solar_data.columns.str.replace('_pv$', '', regex=True)\n",
    "solar_data.columns = solar_data.columns.str.replace('S', 's')\n",
    "solar_data['time'] = solar_data.index\n",
    "\n",
    "# Compute the maximum solar production for each node.\n",
    "# Assume node names are the columns in solar_data except for 'time'\n",
    "node_names = [col for col in solar_data.columns if col != 'time']\n",
    "max_solar = solar_data[node_names].max()\n",
    "\n",
    "# Create a single-row DataFrame where column names are the node names\n",
    "# and the single row contains the max solar production (used as SBAR per node).\n",
    "max_solar_df = pd.DataFrame([max_solar])\n",
    "\n",
    "# Save this DataFrame to a CSV file in the data folder.\n",
    "output_csv_path = os.path.join(config.DATA_DIR, \"max_solar_production.csv\")\n",
    "max_solar_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Max solar production per node saved to\", output_csv_path)\n",
    "\n",
    "# Immediately read back the file to create the sbar_df DataFrame.\n",
    "sbar_df = pd.read_csv(output_csv_path)\n",
    "\n",
    "# Import load data. Convert any capital \"S\" in the column names to lower-case.\n",
    "load_data = pd.read_csv(f\"{config.DATA_DIR}/load_data.csv\")\n",
    "load_data.columns = load_data.columns.str.replace('S', 's')\n",
    "load_data['time'] = load_data.index\n",
    "load_data.sort_values('time', inplace=True)\n",
    "\n",
    "# Import the solar voltage breakpoints data and convert all capital \"S\" to lower-case.\n",
    "breaking_points = pd.read_csv(f\"{config.DATA_DIR}/solar_VV_breakpoints.csv\")\n",
    "breaking_points.columns = breaking_points.columns.str.replace('_pv$', '', regex=True)\n",
    "breaking_points.columns = breaking_points.columns.str.replace('S', 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELICS Broker Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_broker():\n",
    "    global broker\n",
    "    broker = h.helicsCreateBroker(\"zmq\", \"\", \"--federates=3 --loglevel=warning\")\n",
    "\n",
    "broker_thread = threading.Thread(target=start_broker, daemon=True)\n",
    "broker_thread.start()\n",
    "time.sleep(1)  # Allow broker to initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the Federates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the voltage consumer federate in its own thread.\n",
    "consumer_thread = threading.Thread(\n",
    "    target=voltage_consumer_federate.run_voltage_consumer_federate,\n",
    "    args=(solar_data, load_data, node_names, config.SIMULATION_TIME, config.TIME_STEP)\n",
    ")\n",
    "\n",
    "# Launch the OpenDSS federate in its own thread.\n",
    "opendss_thread = threading.Thread(target=opendss_federate.run_opendss_federate)\n",
    "\n",
    "# Launch the inverter federate in its own thread.\n",
    "# Pass both the breakpoints DataFrame and the sbar_df (node-specific SBAR values).\n",
    "inverter_thread = threading.Thread(\n",
    "    target=inverter_federate.run_inverter_federate,\n",
    "    args=(node_names, config.SIMULATION_TIME, config.TIME_STEP, breaking_points, sbar_df)\n",
    ")\n",
    "\n",
    "# Start federates.\n",
    "consumer_thread.start()\n",
    "time.sleep(1.0)  # Ensure the consumer starts publishing before OpenDSS starts.\n",
    "opendss_thread.start()\n",
    "time.sleep(0.5)  # Optional delay for proper initialization.\n",
    "inverter_thread.start()\n",
    "\n",
    "# Wait for all federate threads to complete.\n",
    "consumer_thread.join()\n",
    "opendss_thread.join()\n",
    "inverter_thread.join()\n",
    "\n",
    "# =============================================================================\n",
    "# Shutdown Broker\n",
    "# =============================================================================\n",
    "if 'broker' in globals() and h.helicsBrokerIsConnected(broker):\n",
    "    h.helicsBrokerDisconnect(broker)\n",
    "    h.helicsBrokerFree(broker)\n",
    "\n",
    "print(\"Simulation complete. Broker closed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the voltage timeseries data\n",
    "df = pd.read_csv(\"voltage_timeseries.csv\")\n",
    "\n",
    "# --- Choose Your Plotting Option ---\n",
    "\n",
    "# None for all nodes, array of strings for specific nodes\n",
    "nodes_to_plot = [\"701a\", \"701b\", \"701c\", \"727a\", \"727b\", \"727c\"]\n",
    "#nodes_to_plot = None\n",
    "\n",
    "# --- Determine Which Nodes to Plot ---\n",
    "if nodes_to_plot is None or len(nodes_to_plot) == 0:\n",
    "    # Automatically choose all columns except the \"time\" column.\n",
    "    nodes_to_plot = [col for col in df.columns if col != \"time\"]\n",
    "else:\n",
    "    # Check that each specified node exists in the DataFrame.\n",
    "    missing = [n for n in nodes_to_plot if n not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"[ERROR] The following nodes are missing in the CSV: {missing}\")\n",
    "        print(\"Available nodes:\", list(df.columns))\n",
    "        exit()\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "for node in nodes_to_plot:\n",
    "    plt.plot(df['time'], df[node], label=node)\n",
    "\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Voltage Magnitude [pu]\")\n",
    "plt.title(\"Voltage Magnitude Over Time\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magic_exp_PG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
